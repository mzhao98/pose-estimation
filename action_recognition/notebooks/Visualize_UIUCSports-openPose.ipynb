{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# import keras\n",
    "# import keras.backend as K\n",
    "# from skimage.util.montage import montage2d\n",
    "# from skimage.io import imread\n",
    "# from scipy.io import loadmat # for loading mat files\n",
    "# from tqdm import tqdm_notebook\n",
    "# root_mpi_dir = os.path.join('..', 'data', 'MPII')\n",
    "# data_dir = os.path.join(root_mpi_dir, 'Data')\n",
    "# annot_dir = os.path.join(root_mpi_dir, 'Annotation Subset') # annotations the important part of the data\n",
    "# img_dir = os.path.join(data_dir, 'Original')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from os import listdir\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import scipy.io as sio\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = {\n",
    "    0: 'rowing',\n",
    "    1: 'badminton',\n",
    "    2: 'polo',\n",
    "    3: 'bocce',\n",
    "    4: 'snowboarding',\n",
    "    5: 'croquet',\n",
    "    6: 'sailing',\n",
    "    7: 'rockclimbing',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = {v: k for k, v in index_to_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpii_path = '../data/MPII'\n",
    "images_path = os.path.join('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in listdir(images_path) if isfile(join(images_path, f))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {}\n",
    "label_dict = {}\n",
    "\n",
    "index = 0\n",
    "# for i in range(len(image_files)):\n",
    "for i in range(100):\n",
    "    im = image_files[i]\n",
    "    if 'Thumb' in im or '.DS' in im:\n",
    "        continue\n",
    "    if 'rar' in im:\n",
    "        continue\n",
    "#     print(im)\n",
    "    label_str = im.split('_')[2].lower()\n",
    "    image_dict[index] = im\n",
    "    label_dict[index] = label_to_index[label_str]\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UIUC_Actions_Dataset(data.Dataset):\n",
    "#       '''Characterizes a dataset for PyTorch'''\n",
    "    def __init__(self, labels, images, images_path):\n",
    "        '''Initialization'''\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "        \n",
    "        self.images_path = images_path\n",
    "        \n",
    "        self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize((96, 96)),\n",
    "                    transforms.ToTensor(),\n",
    "#                     transforms.CenterCrop(10),\n",
    "                 \n",
    "                 transforms.Normalize((0.5, 0.5, 0.5), \n",
    "                                      (0.5, 0.5, 0.5))])\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the total number of samples'''\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Generates one sample of data'''\n",
    "        # Select sample\n",
    "        image_filename = self.images[index]\n",
    "        path_to_image = os.path.join(self.images_path, image_filename)\n",
    "\n",
    "        # Load data and get label\n",
    "        image = Image.open(path_to_image)\n",
    "        image = self.transform(image).float()\n",
    "        x = image\n",
    "#         y = torch.tensor(np.array(self.labels[index])).float()\n",
    "\n",
    "#         print(y)\n",
    "        \n",
    "        y = int(self.labels[index])\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UIUC_Actions_Dataset(label_dict, \n",
    "                              image_dict, images_path)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=256,\n",
    "                                          shuffle=True,\n",
    "                                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset) =  100\n"
     ]
    }
   ],
   "source": [
    "print(\"len(train_dataset) = \", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-254bb7a69d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenpose\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyopenpose\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpose'"
     ]
    }
   ],
   "source": [
    "from openpose import pyopenpose as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
